# é¢„æ¡ˆ01: çŸ¥è¯†åº“é›†æˆæ–¹æ¡ˆ

> ç‰ˆæœ¬: v1.11 | ä¼˜å…ˆçº§: ğŸ”´ P0 | **AIå¼€å‘: 3-5å¤©** | äººå·¥å®¡æ ¸: 0.5å¤©

---

## 1. ç›®æ ‡ä¸æˆåŠŸæŒ‡æ ‡

### 1.1 æ ¸å¿ƒç›®æ ‡
- é›†æˆå†å²çŸ¥è¯†åº“ï¼Œæå‡å†å²ç±»å°è¯´å‡†ç¡®æ€§ä» **60%â†’90%**
- å®ç°RAGæ£€ç´¢å¢å¼ºç”Ÿæˆï¼Œ**è‡ªåŠ¨æ³¨å…¥**ç›¸å…³çŸ¥è¯†åˆ°ç« èŠ‚ç”Ÿæˆ
- æ”¯æŒä¸“ä¸šé¢†åŸŸçŸ¥è¯†ï¼ˆç§‘æŠ€/é‡‘è/åŒ»å­¦/å†›äº‹ï¼‰

### 1.2 æˆåŠŸæŒ‡æ ‡

| æŒ‡æ ‡ | å½“å‰ | ç›®æ ‡ | éªŒè¯æ–¹æ³• |
|------|------|------|----------|
| å†å²å‡†ç¡®æ€§ | 60% | 90% | AIè¯„ä¼°+äººå·¥æŠ½æ£€ |
| ä¸“ä¸šæœ¯è¯­å‡†ç¡®æ€§ | 50% | 85% | é¢†åŸŸä¸“å®¶è¯„å®¡ |
| çŸ¥è¯†æ£€ç´¢å“åº”æ—¶é—´ | - | <500ms | æ€§èƒ½æµ‹è¯• |
| çŸ¥è¯†åº“è¦†ç›–ç‡ | 0% | 80% | æ•°æ®ç»Ÿè®¡ |

---

## 2. æ–¹æ¡ˆå¯¹æ¯”

### æ–¹æ¡ˆA: pgvectoræ‰©å±• (æ¨è â­)

**åŸç†**: åˆ©ç”¨ç°æœ‰PostgreSQLï¼Œæ·»åŠ pgvectoræ‰©å±•å®ç°å‘é‡å­˜å‚¨

```
ä¼˜ç‚¹:
âœ… æ— éœ€æ–°å¢æœåŠ¡ï¼Œå¤ç”¨ç°æœ‰PostgreSQL
âœ… äº‹åŠ¡ä¸€è‡´æ€§ï¼ŒçŸ¥è¯†ä¸ä¸šåŠ¡æ•°æ®åŒåº“
âœ… è¿ç»´æˆæœ¬ä½ï¼Œå›¢é˜Ÿå·²ç†Ÿæ‚‰PostgreSQL
âœ… æˆæœ¬æœ€ä½ï¼Œæ— é¢å¤–æœåŠ¡å™¨è´¹ç”¨

ç¼ºç‚¹:
âŒ å¤§è§„æ¨¡(>1000ä¸‡å‘é‡)æ€§èƒ½ä¸‹é™
âŒ ç´¢å¼•é‡å»ºæ—¶é—´è¾ƒé•¿
âŒ é«˜çº§å‘é‡åŠŸèƒ½æœ‰é™

é€‚ç”¨åœºæ™¯: ä¸­å°è§„æ¨¡çŸ¥è¯†åº“(<500ä¸‡æ¡)
```

**æ¶æ„å›¾**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 PostgreSQL 18                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ ä¸šåŠ¡æ•°æ®è¡¨   â”‚  â”‚ çŸ¥è¯†å‘é‡è¡¨ (pgvector)   â”‚  â”‚
â”‚  â”‚ - projects  â”‚  â”‚ - knowledge_entries     â”‚  â”‚
â”‚  â”‚ - chapters  â”‚  â”‚ - historical_figures    â”‚  â”‚
â”‚  â”‚ - charactersâ”‚  â”‚ - historical_events     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                         â”‚                       â”‚
â”‚                    HNSWç´¢å¼•                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æˆæœ¬ä¼°ç®—**:
- æœåŠ¡å™¨: $0/æœˆ (å¤ç”¨ç°æœ‰)
- å­˜å‚¨: +20GB SSD
- ä¸€æ¬¡æ€§: $100 (åµŒå…¥ç”ŸæˆAPI)

---

### æ–¹æ¡ˆB: ChromaDBç‹¬ç«‹æœåŠ¡

**åŸç†**: éƒ¨ç½²ç‹¬ç«‹çš„ChromaDBå‘é‡æ•°æ®åº“æœåŠ¡

```
ä¼˜ç‚¹:
âœ… ä¸“ä¸ºå‘é‡æœç´¢ä¼˜åŒ–
âœ… ç®€å•æ˜“ç”¨çš„Python API
âœ… é¡¹ç›®å·²æœ‰ChromaDBé›†æˆç»éªŒ
âœ… æ”¯æŒå¤šç§è·ç¦»åº¦é‡

ç¼ºç‚¹:
âŒ éœ€è¦é¢å¤–æœåŠ¡å™¨èµ„æº
âŒ æ•°æ®ä¸€è‡´æ€§éœ€è¦é¢å¤–å¤„ç†
âŒ ç”Ÿäº§ç¯å¢ƒç¨³å®šæ€§å¾…éªŒè¯

é€‚ç”¨åœºæ™¯: ä¸­ç­‰è§„æ¨¡ï¼Œå¿«é€ŸåŸå‹
```

**æ¶æ„å›¾**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL    â”‚     â”‚    ChromaDB     â”‚
â”‚   (ä¸šåŠ¡æ•°æ®)    â”‚     â”‚   (å‘é‡æ•°æ®)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
              â”‚ çŸ¥è¯†æ£€ç´¢æœåŠ¡ â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æˆæœ¬ä¼°ç®—**:
- æœåŠ¡å™¨: +$50/æœˆ (4æ ¸8G)
- å­˜å‚¨: 100GB SSD
- ä¸€æ¬¡æ€§: $100 (åµŒå…¥ç”Ÿæˆ)

---

### æ–¹æ¡ˆC: Milvusä¼ä¸šçº§æ–¹æ¡ˆ

**åŸç†**: éƒ¨ç½²Milvusåˆ†å¸ƒå¼å‘é‡æ•°æ®åº“

```
ä¼˜ç‚¹:
âœ… äº¿çº§å‘é‡æ”¯æŒ
âœ… åˆ†å¸ƒå¼æ¶æ„ï¼Œé«˜å¯ç”¨
âœ… ä¸°å¯Œçš„ç´¢å¼•ç±»å‹
âœ… ä¼ä¸šçº§ç¨³å®šæ€§

ç¼ºç‚¹:
âŒ éƒ¨ç½²å¤æ‚ï¼Œéœ€è¦K8s
âŒ èµ„æºæ¶ˆè€—å¤§
âŒ å­¦ä¹ æ›²çº¿é™¡å³­
âŒ æˆæœ¬è¾ƒé«˜

é€‚ç”¨åœºæ™¯: å¤§è§„æ¨¡ç”Ÿäº§ç¯å¢ƒ
```

**æˆæœ¬ä¼°ç®—**:
- æœåŠ¡å™¨: +$200/æœˆ (é›†ç¾¤)
- è¿ç»´: éœ€è¦ä¸“äºº
- ä¸€æ¬¡æ€§: $100 (åµŒå…¥ç”Ÿæˆ)

---

## 3. æ¨èæ–¹æ¡ˆ: pgvector (æ–¹æ¡ˆA)

### 3.1 é€‰æ‹©ç†ç”±

1. **ä¸ç°æœ‰æ¶æ„ä¸€è‡´**: é¡¹ç›®å·²ä½¿ç”¨PostgreSQLï¼Œæ— éœ€å¼•å…¥æ–°æŠ€æœ¯æ ˆ
2. **æˆæœ¬æœ€ä¼˜**: æ— é¢å¤–æœåŠ¡å™¨è´¹ç”¨
3. **æ•°æ®ä¸€è‡´æ€§**: çŸ¥è¯†æ•°æ®ä¸ä¸šåŠ¡æ•°æ®åŒåº“ï¼Œäº‹åŠ¡ä¿è¯
4. **è§„æ¨¡é€‚ä¸­**: å†å²çŸ¥è¯†åº“é¢„è®¡<100ä¸‡æ¡ï¼Œpgvectorå®Œå…¨èƒœä»»
5. **å›¢é˜Ÿç†Ÿæ‚‰**: é™ä½å­¦ä¹ å’Œç»´æŠ¤æˆæœ¬

### 3.2 æŠ€æœ¯å®ç°

#### 3.2.1 æ•°æ®åº“Schema

```sql
-- å¯ç”¨pgvectoræ‰©å±•
CREATE EXTENSION IF NOT EXISTS vector;

-- çŸ¥è¯†åˆ†ç±»è¡¨
CREATE TABLE knowledge_categories (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    parent_id INTEGER REFERENCES knowledge_categories(id),
    description TEXT,
    created_at TIMESTAMP DEFAULT NOW()
);

-- çŸ¥è¯†æ¡ç›®è¡¨ (æ ¸å¿ƒ)
CREATE TABLE knowledge_entries (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    category_id INTEGER REFERENCES knowledge_categories(id),
    title VARCHAR(500) NOT NULL,
    content TEXT NOT NULL,
    source VARCHAR(500),
    reliability FLOAT DEFAULT 0.8,
    time_period VARCHAR(100),
    tags JSONB,
    embedding vector(1536),  -- OpenAI ada-002ç»´åº¦
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- å†å²äººç‰©è¡¨
CREATE TABLE historical_figures (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(100) NOT NULL,
    aliases JSONB,  -- ["å´‡ç¥¯å¸", "æ˜æ€å®—"]
    birth_year INTEGER,
    death_year INTEGER,
    dynasty VARCHAR(50),
    title VARCHAR(200),
    biography TEXT,
    personality TEXT,
    achievements JSONB,
    relationships JSONB,
    embedding vector(1536),
    created_at TIMESTAMP DEFAULT NOW()
);

-- å†å²äº‹ä»¶è¡¨
CREATE TABLE historical_events (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(200) NOT NULL,
    year_start INTEGER,
    year_end INTEGER,
    dynasty VARCHAR(50),
    location VARCHAR(200),
    description TEXT,
    causes JSONB,
    consequences JSONB,
    key_figures JSONB,
    embedding vector(1536),
    created_at TIMESTAMP DEFAULT NOW()
);

-- åˆ›å»ºHNSWç´¢å¼• (é«˜æ€§èƒ½è¿‘ä¼¼æœç´¢)
CREATE INDEX ON knowledge_entries 
    USING hnsw (embedding vector_cosine_ops)
    WITH (m = 16, ef_construction = 64);

CREATE INDEX ON historical_figures 
    USING hnsw (embedding vector_cosine_ops);

CREATE INDEX ON historical_events 
    USING hnsw (embedding vector_cosine_ops);
```

#### 3.2.2 çŸ¥è¯†æ£€ç´¢æœåŠ¡

```python
# backend/app/services/knowledge_service.py

from typing import List, Dict, Optional
from sqlalchemy import text
from sentence_transformers import SentenceTransformer

class KnowledgeService:
    """çŸ¥è¯†åº“æ£€ç´¢æœåŠ¡ - åŸºäºpgvector"""
    
    def __init__(self, db_session):
        self.db = db_session
        # å¤ç”¨ç°æœ‰çš„embeddingæ¨¡å‹
        self.embedding_model = SentenceTransformer(
            'paraphrase-multilingual-MiniLM-L12-v2'
        )
    
    async def search_knowledge(
        self,
        query: str,
        category: str = None,
        time_period: str = None,
        top_k: int = 5
    ) -> List[Dict]:
        """è¯­ä¹‰æœç´¢çŸ¥è¯†åº“"""
        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_embedding = self.embedding_model.encode(query).tolist()
        
        # æ„å»ºSQL (pgvectorä½™å¼¦ç›¸ä¼¼åº¦)
        sql = """
        SELECT id, title, content, source, reliability,
               1 - (embedding <=> :embedding) as similarity
        FROM knowledge_entries
        WHERE 1=1
        """
        params = {"embedding": str(query_embedding)}
        
        if category:
            sql += " AND category_id = (SELECT id FROM knowledge_categories WHERE name = :category)"
            params["category"] = category
        if time_period:
            sql += " AND time_period = :time_period"
            params["time_period"] = time_period
        
        sql += " ORDER BY embedding <=> :embedding LIMIT :top_k"
        params["top_k"] = top_k
        
        result = await self.db.execute(text(sql), params)
        return [dict(row) for row in result.fetchall()]
    
    async def get_historical_context(
        self,
        dynasty: str,
        year: int = None,
        characters: List[str] = None
    ) -> Dict:
        """è·å–å†å²èƒŒæ™¯ä¸Šä¸‹æ–‡ (ç”¨äºç« èŠ‚ç”Ÿæˆ)"""
        context = {
            "dynasty_info": await self._get_dynasty_info(dynasty),
            "period_events": [],
            "cultural_notes": [],
            "figure_info": []
        }
        
        # è·å–æ—¶æœŸäº‹ä»¶
        if year:
            events = await self._search_events_by_year(dynasty, year)
            context["period_events"] = events[:5]
        
        # è·å–æ¶‰åŠäººç‰©ä¿¡æ¯
        if characters:
            for name in characters:
                figure = await self._search_figure(name, dynasty)
                if figure:
                    context["figure_info"].append(figure)
        
        return context
    
    async def validate_historical_accuracy(
        self,
        content: str,
        dynasty: str,
        year: int = None
    ) -> Dict:
        """AIéªŒè¯å†å²å‡†ç¡®æ€§ (è‡ªåŠ¨åŒ–ï¼Œæ— éœ€äººå·¥)"""
        issues = []
        
        # 1. æå–å†…å®¹ä¸­çš„å®ä½“
        entities = await self._extract_entities(content)
        
        # 2. éªŒè¯äººç‰©
        for person in entities.get("persons", []):
            figure = await self._search_figure(person, dynasty)
            if figure:
                # æ£€æŸ¥ç”Ÿå’å¹´
                if year and figure.get("death_year") and year > figure["death_year"]:
                    issues.append({
                        "type": "anachronism",
                        "entity": person,
                        "issue": f"{person}å·²äº{figure['death_year']}å¹´å»ä¸–",
                        "suggestion": f"è°ƒæ•´æ—¶é—´çº¿æˆ–ç§»é™¤{person}"
                    })
        
        # 3. éªŒè¯ç‰©å“/ç§‘æŠ€
        for item in entities.get("items", []):
            anachronism = await self._check_item_anachronism(item, dynasty, year)
            if anachronism:
                issues.append(anachronism)
        
        return {
            "is_accurate": len(issues) == 0,
            "accuracy_score": max(0, 1 - len(issues) * 0.1),
            "issues": issues,
            "auto_fix_available": len(issues) > 0
        }
    
    async def _extract_entities(self, content: str) -> Dict:
        """ä½¿ç”¨AIæå–å®ä½“ (äººç‰©ã€åœ°ç‚¹ã€ç‰©å“)"""
        # è°ƒç”¨ç°æœ‰AIæœåŠ¡
        prompt = f"""ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–å®ä½“ï¼Œè¿”å›JSONæ ¼å¼ï¼š
        {{
            "persons": ["äººç‰©1", "äººç‰©2"],
            "locations": ["åœ°ç‚¹1"],
            "items": ["ç‰©å“1"],
            "events": ["äº‹ä»¶1"]
        }}
        
        æ–‡æœ¬ï¼š{content[:2000]}
        """
        # è°ƒç”¨AIæå–
        result = await self.ai_service.generate(prompt, max_tokens=500)
        return json.loads(result)
```

---

## 4. æ•°æ®å‡†å¤‡æ–¹æ¡ˆ

### 4.1 æ•°æ®æºä¸è·å–æ–¹å¼

| æ•°æ®æº | å†…å®¹ | æ•°æ®é‡ | è·å–æ–¹å¼ | å¯ä¿¡åº¦ |
|--------|------|--------|----------|--------|
| ç»´åŸºç™¾ç§‘API | å†å²äº‹ä»¶ã€äººç‰© | ~50ä¸‡æ¡ | APIçˆ¬å– | é«˜ |
| ä¸­å›½å†å²å¹´è¡¨ | æœä»£ã€å¹´å· | ~5000æ¡ | å…¬å¼€æ•°æ®æ•´ç† | é«˜ |
| ç™¾åº¦ç™¾ç§‘ | è¡¥å……äººç‰©èµ„æ–™ | ~10ä¸‡æ¡ | API/çˆ¬å– | ä¸­ |
| å†å²åœ°å›¾æ•°æ® | åœ°åå˜è¿ | ~2ä¸‡æ¡ | å…¬å¼€æ•°æ® | é«˜ |
| æ–‡åŒ–ä¹ ä¿—èµ„æ–™ | æœé¥°ã€ç¤¼ä»ª | ~1ä¸‡æ¡ | äººå·¥æ•´ç† | é«˜ |

### 4.2 æ•°æ®å¤„ç†Pipeline

```python
# scripts/import_knowledge.py

async def import_historical_data():
    """å¯¼å…¥å†å²æ•°æ®çš„å®Œæ•´æµç¨‹"""
    
    # é˜¶æ®µ1: å¯¼å…¥æœä»£åŸºç¡€æ•°æ®
    print("ğŸ“š å¯¼å…¥æœä»£æ•°æ®...")
    dynasties = load_json("data/dynasties.json")
    for d in dynasties:
        await db.execute(insert(KnowledgeCategory).values(
            name=d["name"],
            description=d["description"]
        ))
    
    # é˜¶æ®µ2: å¯¼å…¥å†å²äººç‰© (æ‰¹é‡åµŒå…¥)
    print("ğŸ‘¤ å¯¼å…¥å†å²äººç‰©...")
    figures = load_json("data/historical_figures.json")
    
    # æ‰¹é‡ç”ŸæˆåµŒå…¥ (èŠ‚çœAPIè°ƒç”¨)
    texts = [f"{f['name']} {f['biography'][:500]}" for f in figures]
    embeddings = embedding_model.encode(texts, batch_size=32, show_progress_bar=True)
    
    for i, figure in enumerate(figures):
        figure['embedding'] = embeddings[i].tolist()
        await db.execute(insert(HistoricalFigure).values(**figure))
    
    # é˜¶æ®µ3: å¯¼å…¥å†å²äº‹ä»¶
    print("ğŸ“… å¯¼å…¥å†å²äº‹ä»¶...")
    events = load_json("data/historical_events.json")
    texts = [f"{e['name']} {e['description'][:500]}" for e in events]
    embeddings = embedding_model.encode(texts, batch_size=32)
    
    for i, event in enumerate(events):
        event['embedding'] = embeddings[i].tolist()
        await db.execute(insert(HistoricalEvent).values(**event))
    
    print("âœ… æ•°æ®å¯¼å…¥å®Œæˆ!")
```

### 4.3 æ•°æ®æ ¼å¼ç¤ºä¾‹

```json
// data/historical_figures.json
[
  {
    "name": "æœ±ç”±æ£€",
    "aliases": ["å´‡ç¥¯å¸", "æ˜æ€å®—", "æœ±ç”±æ£€"],
    "birth_year": 1611,
    "death_year": 1644,
    "dynasty": "æ˜æœ",
    "title": "æ˜æœç¬¬åå…­ä½çš‡å¸",
    "biography": "æœ±ç”±æ£€ï¼ˆ1611å¹´2æœˆ6æ—¥ï¼1644å¹´4æœˆ25æ—¥ï¼‰ï¼Œæ˜æœæœ«ä»£çš‡å¸ã€‚å¹´å·å´‡ç¥¯ï¼Œåœ¨ä½åä¸ƒå¹´ã€‚å³ä½åé“²é™¤é­å¿ è´¤é˜‰å…šï¼Œå‹¤äºæ”¿äº‹ï¼Œä½†ç”Ÿæ€§å¤šç–‘ï¼Œåˆšæ„è‡ªç”¨ã€‚é¢å¯¹å†…å¿§å¤–æ‚£ï¼Œæœ€ç»ˆäº1644å¹´æè‡ªæˆæ”»å…¥åŒ—äº¬æ—¶è‡ªç¼¢äºç…¤å±±ã€‚",
    "personality": "å‹¤æ”¿ã€å¤šç–‘ã€åˆšæ„è‡ªç”¨ã€èŠ‚ä¿­ã€æ€¥èº",
    "achievements": ["é“²é™¤é­å¿ è´¤", "æ•´é¡¿æœçº²", "å‡å…èµ‹ç¨"],
    "relationships": {
      "çˆ¶äº²": "æ˜å…‰å®—æœ±å¸¸æ´›",
      "çš‡å": "å‘¨çš‡å",
      "é‡è‡£": ["è¢å´‡ç„•", "å­™æ‰¿å®—", "å¢è±¡å‡", "æ´ªæ‰¿ç•´"]
    }
  }
]
```

---

## 5. é›†æˆåˆ°ç« èŠ‚ç”Ÿæˆ

### 5.1 ä¿®æ”¹ç« èŠ‚ç”Ÿæˆæµç¨‹

```python
# backend/app/services/chapter_generation_service.py

async def generate_chapter_with_knowledge(
    self,
    chapter: Chapter,
    project: Project
) -> str:
    """å¸¦çŸ¥è¯†å¢å¼ºçš„ç« èŠ‚ç”Ÿæˆ"""
    
    # 1. åˆ¤æ–­æ˜¯å¦éœ€è¦çŸ¥è¯†å¢å¼º
    if project.genre not in ["å†å²", "å†å²ç©¿è¶Š", "æ¶ç©ºå†å²"]:
        return await self.generate_chapter_normal(chapter, project)
    
    # 2. è·å–å†å²èƒŒæ™¯ä¸Šä¸‹æ–‡
    knowledge_context = await self.knowledge_service.get_historical_context(
        dynasty=project.world_time_period,
        year=getattr(chapter, 'story_year', None),
        characters=[c.name for c in chapter.involved_characters]
    )
    
    # 3. æ ¼å¼åŒ–çŸ¥è¯†ä¸Šä¸‹æ–‡
    knowledge_prompt = self._format_knowledge_context(knowledge_context)
    
    # 4. æ„å»ºå¢å¼ºæç¤ºè¯
    enhanced_prompt = f"""
ã€å†å²èƒŒæ™¯çŸ¥è¯†ã€‘
{knowledge_prompt}

---
åŸºäºä»¥ä¸Šå†å²èƒŒæ™¯ï¼Œè¯·åˆ›ä½œä»¥ä¸‹ç« èŠ‚ã€‚æ³¨æ„ï¼š
- ç¡®ä¿å†å²ç»†èŠ‚å‡†ç¡®ï¼ˆäººç‰©ã€äº‹ä»¶ã€æ—¶é—´ï¼‰
- ä½¿ç”¨ç¬¦åˆæ—¶ä»£çš„è¯­è¨€å’Œç§°è°“
- é¿å…å‡ºç°æ—¶ä»£é”™è¯¯ï¼ˆå¦‚æ˜æœå‡ºç°æ¸…æœç‰©å“ï¼‰

{self.original_prompt}
"""
    
    # 5. ç”Ÿæˆç« èŠ‚
    content = await self.ai_service.generate(enhanced_prompt)
    
    # 6. è‡ªåŠ¨éªŒè¯å‡†ç¡®æ€§
    validation = await self.knowledge_service.validate_historical_accuracy(
        content=content,
        dynasty=project.world_time_period
    )
    
    # 7. å¦‚æœæœ‰é—®é¢˜ï¼Œå°è¯•è‡ªåŠ¨ä¿®å¤
    if not validation["is_accurate"] and validation["auto_fix_available"]:
        content = await self._auto_fix_historical_issues(
            content, validation["issues"]
        )
    
    return content
```

---

## 6. APIè®¾è®¡

### 6.1 æ–°å¢APIç«¯ç‚¹

```python
# backend/app/api/knowledge.py

@router.get("/knowledge/search")
async def search_knowledge(
    query: str,
    category: str = None,
    time_period: str = None,
    limit: int = 10
) -> List[KnowledgeEntry]:
    """æœç´¢çŸ¥è¯†åº“"""

@router.get("/knowledge/figures")
async def search_figures(
    name: str = None,
    dynasty: str = None,
    limit: int = 10
) -> List[HistoricalFigure]:
    """æœç´¢å†å²äººç‰©"""

@router.get("/knowledge/events")
async def search_events(
    keyword: str = None,
    dynasty: str = None,
    year_start: int = None,
    year_end: int = None
) -> List[HistoricalEvent]:
    """æœç´¢å†å²äº‹ä»¶"""

@router.post("/knowledge/validate")
async def validate_content(
    content: str,
    dynasty: str,
    year: int = None
) -> ValidationResult:
    """éªŒè¯å†…å®¹å†å²å‡†ç¡®æ€§"""

@router.get("/knowledge/context/{project_id}")
async def get_project_context(
    project_id: str,
    chapter_number: int = None
) -> KnowledgeContext:
    """è·å–é¡¹ç›®ç›¸å…³çŸ¥è¯†ä¸Šä¸‹æ–‡"""
```

### 6.2 MCPå·¥å…·æ‰©å±•

```python
# mcp_novel_server.py æ–°å¢å·¥å…·

Tool(
    name="novel_search_knowledge",
    description="æœç´¢çŸ¥è¯†åº“è·å–èƒŒæ™¯èµ„æ–™",
    inputSchema={
        "type": "object",
        "properties": {
            "query": {"type": "string"},
            "category": {"type": "string", "enum": ["å†å²", "ç§‘æŠ€", "é‡‘è", "åŒ»å­¦", "å†›äº‹"]},
            "time_period": {"type": "string"}
        },
        "required": ["query"]
    }
),

Tool(
    name="novel_search_figure",
    description="æœç´¢å†å²äººç‰©ä¿¡æ¯",
    inputSchema={
        "type": "object",
        "properties": {
            "name": {"type": "string"},
            "dynasty": {"type": "string"}
        },
        "required": ["name"]
    }
),

Tool(
    name="novel_validate_history",
    description="éªŒè¯å†…å®¹çš„å†å²å‡†ç¡®æ€§ï¼ˆè‡ªåŠ¨åŒ–ï¼‰",
    inputSchema={
        "type": "object",
        "properties": {
            "content": {"type": "string"},
            "dynasty": {"type": "string"},
            "year": {"type": "integer"}
        },
        "required": ["content", "dynasty"]
    }
)
```

---

## 7. AIé©±åŠ¨å®æ–½è®¡åˆ’

### 7.1 æ‰§è¡Œæµç¨‹ (3-5å¤©)

```
Day 1 (4å°æ—¶):
â”œâ”€â”€ AI: ç”Ÿæˆpgvector Schema + è¿ç§»è„šæœ¬
â”œâ”€â”€ AI: ç”ŸæˆKnowledgeServiceæ¡†æ¶
â””â”€â”€ äººå·¥: å®¡æ ¸Schemaè®¾è®¡

Day 2 (6å°æ—¶):
â”œâ”€â”€ AI: å®ç°çŸ¥è¯†æ£€ç´¢æœåŠ¡
â”œâ”€â”€ AI: å®ç°å†å²ä¸Šä¸‹æ–‡è·å–
â”œâ”€â”€ AI: ç”ŸæˆAPIç«¯ç‚¹
â””â”€â”€ AI: è‡ªåŠ¨æµ‹è¯•

Day 3 (4å°æ—¶):
â”œâ”€â”€ AI: é›†æˆåˆ°ç« èŠ‚ç”Ÿæˆæµç¨‹
â”œâ”€â”€ AI: å®ç°å‡†ç¡®æ€§éªŒè¯
â””â”€â”€ AI: æ·»åŠ MCPå·¥å…·

Day 4 (4å°æ—¶):
â”œâ”€â”€ AI: æ•°æ®å¯¼å…¥è„šæœ¬
â”œâ”€â”€ AI: æ‰¹é‡åµŒå…¥ç”Ÿæˆ
â””â”€â”€ äººå·¥: é›†æˆæµ‹è¯•

Day 5 (2å°æ—¶):
â”œâ”€â”€ AI: æ–‡æ¡£æ›´æ–°
â””â”€â”€ äººå·¥: æœ€ç»ˆå®¡æ ¸+éƒ¨ç½²
```

### 7.2 AI Agentä»»åŠ¡åˆ†é…

| ä»»åŠ¡ | Agent | é¢„è®¡æ—¶é—´ |
|------|-------|----------|
| Schemaè®¾è®¡ | Kiro | 30åˆ†é’Ÿ |
| æœåŠ¡å®ç° | Claude | 2å°æ—¶ |
| APIå¼€å‘ | Claude | 1å°æ—¶ |
| æµ‹è¯•ç”Ÿæˆ | Claude | 30åˆ†é’Ÿ |
| æ–‡æ¡£æ›´æ–° | Claude | 30åˆ†é’Ÿ |

---

## 8. é£é™©ä¸åº”å¯¹

| é£é™© | æ¦‚ç‡ | å½±å“ | åº”å¯¹æªæ–½ |
|------|------|------|----------|
| æ•°æ®è´¨é‡ä¸ä½³ | ä¸­ | é«˜ | å¤šæºäº¤å‰éªŒè¯ã€AIè¾…åŠ©æ¸…æ´— |
| pgvectoræ€§èƒ½ä¸è¶³ | ä½ | ä¸­ | ä¼˜åŒ–ç´¢å¼•å‚æ•°ã€åˆ†è¡¨å­˜å‚¨ |
| åµŒå…¥APIæˆæœ¬è¶…æ”¯ | ä¸­ | ä½ | ä½¿ç”¨æœ¬åœ°æ¨¡å‹ã€æ‰¹é‡å¤„ç† |
| çŸ¥è¯†è¿‡æ—¶ | ä½ | ä½ | å®šæœŸæ›´æ–°æœºåˆ¶ |

---

## 9. èµ„æºéœ€æ±‚ (AIé©±åŠ¨æ¨¡å¼)

### 9.1 æ—¶é—´
- AIå¼€å‘: 3-5å¤©
- äººå·¥å®¡æ ¸: 0.5å¤©
- **æ€»è®¡: 4-5å¤©** (vs ä¼ ç»Ÿ30å¤©)

### 9.2 æˆæœ¬
- APIè°ƒç”¨ (å¼€å‘æœŸ): $50
- åµŒå…¥ç”Ÿæˆ: $50 (ä¸€æ¬¡æ€§)
- æœåŠ¡å™¨: $0/æœˆ (å¤ç”¨PostgreSQL)
- **æ€»è®¡: $100 ä¸€æ¬¡æ€§**

---

*æœ€åæ›´æ–°: 2026-01-05*
